{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5b2c7b41-96b3-42ca-a803-c181f1e12a0d",
   "metadata": {},
   "source": [
    "NLTK Tokenize: Split the text sentence/paragraph into a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849584f8-9cca-4ac5-9837-13cf070a3083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hetvidesai\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\hetvidesai\\anaconda3\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\hetvidesai\\anaconda3\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hetvidesai\\anaconda3\\lib\\site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hetvidesai\\anaconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hetvidesai\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1930f98b-4347-4ef2-b1c5-f75d8b3d903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original string:\n",
      "\n",
      "Joe waited for the train. The train was late. \n",
      "Mary and Samantha took the bus. \n",
      "I looked for Mary and Samantha at the bus station.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "Joe waited for the train. The train was late. \n",
    "Mary and Samantha took the bus. \n",
    "I looked for Mary and Samantha at the bus station.\n",
    "'''\n",
    "print(\"\\nOriginal string:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66f52ea-714a-43cd-902e-74df5f4e93f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\HetviDesai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a42a61-a9fd-4ad2-9742-edc6d91308fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence-tokenized copy in a list:\n",
      "['\\nJoe waited for the train.', 'The train was late.', 'Mary and Samantha took the bus.', 'I looked for Mary and Samantha at the bus station.']\n",
      "\n",
      "Read the list:\n",
      "\n",
      "Joe waited for the train.\n",
      "The train was late.\n",
      "Mary and Samantha took the bus.\n",
      "I looked for Mary and Samantha at the bus station.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "token_text = sent_tokenize(text)\n",
    "print(\"\\nSentence-tokenized copy in a list:\")\n",
    "print(token_text)\n",
    "print(\"\\nRead the list:\")\n",
    "for s in token_text:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71abf0b0-9959-46f5-8753-84de2c19a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joe', 'waited', 'for', 'the', 'train', '.', 'The', 'train', 'was', 'late', '.', 'Mary', 'and', 'Samantha', 'took', 'the', 'bus', '.', 'I', 'looked', 'for', 'Mary', 'and', 'Samantha', 'at', 'the', 'bus', 'station', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokens=word_tokenize(text)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0455d53-6bfb-46aa-8567-a17bc89970a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
